{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 15:37:04.479369: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "1/1 [==============================] - 0s 140ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "1/1 [==============================] - 0s 78ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "1/1 [==============================] - 0s 76ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd17e7eb9a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd180118160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 73ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "1/1 [==============================] - 0s 75ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/nm0wfbb171d9c334vpmqgsg80000gn/T/ipykernel_75442/3711339068.py:74: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize((400, 400), Image.ANTIALIAS)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 56)\n",
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danieljones/anaconda3/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QLabel, QPushButton, QVBoxLayout, QWidget, QFileDialog\n",
    "from PyQt5.QtGui import QPixmap\n",
    "from PIL import Image\n",
    "from PyQt5.QtGui import QImage\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setWindowTitle(\"Component Identification\")\n",
    "        \n",
    "        self.image_label = QLabel(self)\n",
    "        self.image_label.setFixedSize(400, 400)\n",
    "        \n",
    "        self.result_label = QLabel(self)\n",
    "        \n",
    "        upload_button = QPushButton(\"Upload Image\", self)\n",
    "        upload_button.clicked.connect(self.upload_image)\n",
    "        \n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(upload_button)\n",
    "        layout.addWidget(self.image_label)\n",
    "        layout.addWidget(self.result_label)\n",
    "        \n",
    "        central_widget = QWidget(self)\n",
    "        central_widget.setLayout(layout)\n",
    "        self.setCentralWidget(central_widget)\n",
    "    \n",
    "    def upload_image(self):\n",
    "        file_dialog = QFileDialog()\n",
    "        image_path, _ = file_dialog.getOpenFileName(self, \"Select Image\", \"\", \"Image Files (*.png *.jpg *.jpeg)\")\n",
    "        \n",
    "        if image_path:\n",
    "            # Process the image\n",
    "            processed_image = process_image(image_path)\n",
    "            \n",
    "            # Display the processed image\n",
    "            self.display_image(processed_image)\n",
    "            \n",
    "            # Identify the component using your machine learning algorithm\n",
    "            identified_component = identify_component(processed_image, image_path)\n",
    "            \n",
    "            # Display the result\n",
    "            self.result_label.setText(f\"Identified Component: {identified_component}\")\n",
    "    \n",
    "    def display_image(self, image):\n",
    "        image = image.convert(\"RGBA\")  # Convert PIL Image to RGBA mode\n",
    "        data = image.tobytes(\"raw\", \"RGBA\")  # Get the image data bytes\n",
    "        qimage = QImage(data, image.size[0], image.size[1], QImage.Format_RGBA8888)  # Create a QImage from the image data\n",
    "        pixmap = QPixmap.fromImage(qimage)  # Convert QImage to QPixmap\n",
    "        self.image_label.setPixmap(pixmap)\n",
    "    \n",
    "def process_image(image_path):\n",
    "    # Implement your image processing logic here\n",
    "    # You can use libraries like OpenCV or PIL to load and preprocess the image\n",
    "    # Return the processed image\n",
    "    \n",
    "    # Example: Resizing the image to fit the label size\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((400, 400), Image.ANTIALIAS)\n",
    "    \n",
    "\n",
    "    \n",
    "    return image\n",
    "\n",
    "def identify_component(image, image_path):\n",
    "    # Implement your machine learning algorithm to identify the component in the image\n",
    "    # Return the identified component\n",
    "    \n",
    "    # Example: Randomly select a component\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        # Resize the image if necessary\n",
    "        img = cv2.resize(img, (56, 56))\n",
    "        # Convert the image to grayscale if needed\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        img = np.array(img)/255\n",
    "\n",
    "\n",
    "\n",
    "    print(np.shape(img))\n",
    "\n",
    "\n",
    "    loaded_model = models.load_model('ModelGUIV1')\n",
    "    components = [\"Ground\", \"Resistor\", \"Inductor\", \"Capacitor\", \"Battery\"]\n",
    "    index = np.argmax(loaded_model.predict(np.expand_dims(img,axis=0)))\n",
    "    return components[index]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    window = MainWindow()\n",
    "    window.show()\n",
    "    sys.exit(app.exec_())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
